{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b423f9e-bc01-4bc5-9165-5d6bbdc259b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='myenv\\\\Scripts\\\\activate', returncode=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Create a virtual environment named 'myenv'\n",
    "subprocess.run([sys.executable, '-m', 'venv', 'myenv'])\n",
    "\n",
    "# Activate the virtual environment (for Windows)\n",
    "activate_script = 'myenv\\\\Scripts\\\\activate' if sys.platform == 'win32' else 'source myenv/bin/activate'\n",
    "subprocess.run(activate_script, shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "536d3e4b-936f-45be-abc9-29ac87545234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from gym) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from gym) (2.2.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from gym) (0.0.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d27011a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (2.2.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from stable-baselines3) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from stable-baselines3) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.13 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from stable-baselines3) (2.2.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from stable-baselines3) (2.2.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from stable-baselines3) (2.1.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from stable-baselines3) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (4.9.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (0.0.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from torch>=1.13->stable-baselines3) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from torch>=1.13->stable-baselines3) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from torch>=1.13->stable-baselines3) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from torch>=1.13->stable-baselines3) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from torch>=1.13->stable-baselines3) (2023.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from matplotlib->stable-baselines3) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from matplotlib->stable-baselines3) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from matplotlib->stable-baselines3) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from matplotlib->stable-baselines3) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from matplotlib->stable-baselines3) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from matplotlib->stable-baselines3) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from matplotlib->stable-baselines3) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from pandas->stable-baselines3) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from pandas->stable-baselines3) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from jinja2->torch>=1.13->stable-baselines3) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from sympy->torch>=1.13->stable-baselines3) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade stable-baselines3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05901223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from stable-baselines3[extra]) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from stable-baselines3[extra]) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.13 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from stable-baselines3[extra]) (2.2.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from stable-baselines3[extra]) (2.2.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from stable-baselines3[extra]) (2.1.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from stable-baselines3[extra]) (3.8.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from stable-baselines3[extra]) (4.9.0.80)\n",
      "Requirement already satisfied: pygame in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from stable-baselines3[extra]) (2.5.2)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from stable-baselines3[extra]) (2.16.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from stable-baselines3[extra]) (5.9.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from stable-baselines3[extra]) (4.65.0)\n",
      "Requirement already satisfied: rich in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from stable-baselines3[extra]) (13.3.5)\n",
      "Requirement already satisfied: shimmy~=1.3.0 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from stable-baselines3[extra]) (10.2.0)\n",
      "Requirement already satisfied: autorom~=0.6.1 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: click in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (8.1.7)\n",
      "Requirement already satisfied: requests in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2.31.0)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (4.9.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (0.0.4)\n",
      "Requirement already satisfied: ale-py~=0.8.1 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]) (0.8.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.62.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.4.1)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (68.2.2)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.2.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (2023.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2023.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.15.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from tqdm->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]) (6.3.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->stable-baselines3[extra]) (0.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from sympy->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26c4eae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from moviepy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from moviepy) (2.31.0)\n",
      "Requirement already satisfied: proglog<=1.0.0 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from moviepy) (1.26.4)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from moviepy) (2.33.1)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from moviepy) (0.4.9)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from imageio<3.0,>=2.5->moviepy) (10.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from imageio-ffmpeg>=0.2.0->moviepy) (68.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\great woman\\newfoldercmd\\lib\\site-packages (from tqdm<5.0,>=4.11.2->moviepy) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install moviepy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5c4449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.dqn.policies import CnnPolicy\n",
    "from gym.wrappers import ResizeObservation\n",
    "from gym.utils import save_video\n",
    "from PIL import Image\n",
    "\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "from gym.utils.save_video import save_video\n",
    "import warnings\n",
    "\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc6d2e43-7081-4343-8701-cb6166462d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CARTPOLE GAME \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ba261c7-826e-498c-a576-19cb680ee205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing the CustomCartPole game randomly for 20 episodes\n",
      "Episode 1: [11.]\n",
      "Episode 2: [16.]\n",
      "Episode 3: [39.]\n",
      "Episode 4: [44.]\n",
      "Episode 5: [11.]\n",
      "Episode 6: [39.]\n",
      "Episode 7: [13.]\n",
      "Episode 8: [39.]\n",
      "Episode 9: [40.]\n",
      "Episode 10: [24.]\n",
      "Episode 11: [17.]\n",
      "Episode 12: [60.]\n",
      "Episode 13: [13.]\n",
      "Episode 14: [32.]\n",
      "Episode 15: [15.]\n",
      "Episode 16: [29.]\n",
      "Episode 17: [12.]\n",
      "Episode 18: [18.]\n",
      "Episode 19: [13.]\n",
      "Episode 20: [21.]\n",
      "Eval num_timesteps=20000, episode_reward=10.00 +/- 0.00\n",
      "Episode length: 10.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=40000, episode_reward=8.80 +/- 0.40\n",
      "Episode length: 8.80 +/- 0.40\n",
      "Eval num_timesteps=60000, episode_reward=9.00 +/- 0.63\n",
      "Episode length: 9.00 +/- 0.63\n",
      "Eval num_timesteps=80000, episode_reward=27.40 +/- 11.72\n",
      "Episode length: 27.40 +/- 11.72\n",
      "New best mean reward!\n",
      "Eval num_timesteps=100000, episode_reward=201.20 +/- 18.37\n",
      "Episode length: 201.20 +/- 18.37\n",
      "New best mean reward!\n",
      "Eval num_timesteps=120000, episode_reward=457.60 +/- 52.39\n",
      "Episode length: 457.60 +/- 52.39\n",
      "New best mean reward!\n",
      "Eval num_timesteps=140000, episode_reward=9.80 +/- 0.98\n",
      "Episode length: 9.80 +/- 0.98\n",
      "Eval num_timesteps=160000, episode_reward=9.60 +/- 0.49\n",
      "Episode length: 9.60 +/- 0.49\n",
      "Eval num_timesteps=180000, episode_reward=305.80 +/- 59.68\n",
      "Episode length: 305.80 +/- 59.68\n",
      "Eval num_timesteps=200000, episode_reward=417.80 +/- 78.32\n",
      "Episode length: 417.80 +/- 78.32\n",
      "Eval num_timesteps=220000, episode_reward=326.60 +/- 35.63\n",
      "Episode length: 326.60 +/- 35.63\n",
      "Eval num_timesteps=240000, episode_reward=221.40 +/- 12.40\n",
      "Episode length: 221.40 +/- 12.40\n",
      "Eval num_timesteps=260000, episode_reward=225.60 +/- 14.26\n",
      "Episode length: 225.60 +/- 14.26\n",
      "Eval num_timesteps=280000, episode_reward=138.40 +/- 4.50\n",
      "Episode length: 138.40 +/- 4.50\n",
      "Eval num_timesteps=300000, episode_reward=150.20 +/- 5.74\n",
      "Episode length: 150.20 +/- 5.74\n",
      "Eval num_timesteps=320000, episode_reward=179.80 +/- 11.55\n",
      "Episode length: 179.80 +/- 11.55\n",
      "Eval num_timesteps=340000, episode_reward=282.00 +/- 50.09\n",
      "Episode length: 282.00 +/- 50.09\n",
      "Eval num_timesteps=360000, episode_reward=300.40 +/- 32.53\n",
      "Episode length: 300.40 +/- 32.53\n",
      "Eval num_timesteps=380000, episode_reward=148.40 +/- 4.76\n",
      "Episode length: 148.40 +/- 4.76\n",
      "Eval num_timesteps=400000, episode_reward=10.00 +/- 0.63\n",
      "Episode length: 10.00 +/- 0.63\n",
      "Eval num_timesteps=420000, episode_reward=72.60 +/- 6.97\n",
      "Episode length: 72.60 +/- 6.97\n",
      "Eval num_timesteps=440000, episode_reward=93.80 +/- 1.47\n",
      "Episode length: 93.80 +/- 1.47\n",
      "Eval num_timesteps=460000, episode_reward=145.40 +/- 5.95\n",
      "Episode length: 145.40 +/- 5.95\n",
      "Eval num_timesteps=480000, episode_reward=168.20 +/- 12.78\n",
      "Episode length: 168.20 +/- 12.78\n",
      "Eval num_timesteps=500000, episode_reward=146.60 +/- 6.71\n",
      "Episode length: 146.60 +/- 6.71\n",
      "Eval num_timesteps=520000, episode_reward=134.80 +/- 12.69\n",
      "Episode length: 134.80 +/- 12.69\n",
      "Eval num_timesteps=540000, episode_reward=120.00 +/- 6.84\n",
      "Episode length: 120.00 +/- 6.84\n",
      "Eval num_timesteps=560000, episode_reward=126.40 +/- 4.84\n",
      "Episode length: 126.40 +/- 4.84\n",
      "Eval num_timesteps=580000, episode_reward=99.20 +/- 7.86\n",
      "Episode length: 99.20 +/- 7.86\n",
      "Eval num_timesteps=600000, episode_reward=104.60 +/- 7.61\n",
      "Episode length: 104.60 +/- 7.61\n",
      "Eval num_timesteps=620000, episode_reward=119.20 +/- 6.37\n",
      "Episode length: 119.20 +/- 6.37\n",
      "Eval num_timesteps=640000, episode_reward=142.40 +/- 5.54\n",
      "Episode length: 142.40 +/- 5.54\n",
      "Eval num_timesteps=660000, episode_reward=89.80 +/- 9.68\n",
      "Episode length: 89.80 +/- 9.68\n",
      "Eval num_timesteps=680000, episode_reward=150.60 +/- 9.97\n",
      "Episode length: 150.60 +/- 9.97\n",
      "Eval num_timesteps=700000, episode_reward=103.00 +/- 4.56\n",
      "Episode length: 103.00 +/- 4.56\n",
      "Eval num_timesteps=720000, episode_reward=154.20 +/- 17.09\n",
      "Episode length: 154.20 +/- 17.09\n",
      "Eval num_timesteps=740000, episode_reward=112.20 +/- 6.52\n",
      "Episode length: 112.20 +/- 6.52\n",
      "Eval num_timesteps=760000, episode_reward=116.80 +/- 3.71\n",
      "Episode length: 116.80 +/- 3.71\n",
      "Eval num_timesteps=780000, episode_reward=102.80 +/- 3.66\n",
      "Episode length: 102.80 +/- 3.66\n",
      "Eval num_timesteps=800000, episode_reward=99.80 +/- 3.66\n",
      "Episode length: 99.80 +/- 3.66\n",
      "Eval num_timesteps=820000, episode_reward=92.40 +/- 8.01\n",
      "Episode length: 92.40 +/- 8.01\n",
      "Eval num_timesteps=840000, episode_reward=84.40 +/- 3.38\n",
      "Episode length: 84.40 +/- 3.38\n",
      "Eval num_timesteps=860000, episode_reward=110.40 +/- 5.57\n",
      "Episode length: 110.40 +/- 5.57\n",
      "Eval num_timesteps=880000, episode_reward=76.00 +/- 6.54\n",
      "Episode length: 76.00 +/- 6.54\n",
      "Eval num_timesteps=900000, episode_reward=128.40 +/- 4.32\n",
      "Episode length: 128.40 +/- 4.32\n",
      "Eval num_timesteps=920000, episode_reward=141.20 +/- 9.91\n",
      "Episode length: 141.20 +/- 9.91\n",
      "Eval num_timesteps=940000, episode_reward=156.20 +/- 38.59\n",
      "Episode length: 156.20 +/- 38.59\n",
      "Eval num_timesteps=960000, episode_reward=129.40 +/- 13.12\n",
      "Episode length: 129.40 +/- 13.12\n",
      "Eval num_timesteps=980000, episode_reward=121.60 +/- 3.44\n",
      "Episode length: 121.60 +/- 3.44\n",
      "Eval num_timesteps=1000000, episode_reward=116.40 +/- 4.45\n",
      "Episode length: 116.40 +/- 4.45\n",
      "Episode 1: [129.]\n",
      "Episode 2: [108.]\n",
      "Episode 3: [140.]\n",
      "Episode 4: [123.]\n",
      "Episode 5: [138.]\n",
      "Episode 6: [126.]\n",
      "Episode 7: [127.]\n",
      "Episode 8: [128.]\n",
      "Episode 9: [123.]\n",
      "Episode 10: [116.]\n",
      "Moviepy - Building video C:\\Users\\Great Woman\\Downloads\\CartPole_Models\\DQN_CustomCartPole_Model\\CustomCartPole_Agent_play/CustomCartPole-agent-play-episode-0.mp4.\n",
      "Moviepy - Writing video C:\\Users\\Great Woman\\Downloads\\CartPole_Models\\DQN_CustomCartPole_Model\\CustomCartPole_Agent_play/CustomCartPole-agent-play-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\Great Woman\\Downloads\\CartPole_Models\\DQN_CustomCartPole_Model\\CustomCartPole_Agent_play/CustomCartPole-agent-play-episode-0.mp4\n"
     ]
    }
   ],
   "source": [
    "class CustomCartPoleDQNAgent:\n",
    "    def __init__(self, agent_name=None, env_name=None, eval_frequency=20000, buffer_size=1000):\n",
    "        self.agent_name = agent_name\n",
    "        self.env_name = env_name\n",
    "        self.policy = \"MlpPolicy\"  # policy\n",
    "        self.eval_frequency = eval_frequency\n",
    "        self.buffer_size = buffer_size\n",
    "        self.log_path = os.path.join('C:/Users/Great Woman/Downloads/CartPole_Logs/DQN_' + self.agent_name + '_Log')  # path for logging the training data\n",
    "        self.save_path = os.path.join('C:/Users/Great Woman/Downloads/CartPole_Models/DQN_' + self.agent_name + '_Model')  # path for saving the trained model\n",
    "        self.env = self.make_environment()  # function that creates the environment and agent\n",
    "        self.model = self._build_dqn()  # function that builds the DQN model\n",
    "\n",
    "    def make_environment(self):  # A call to the function that creates the environment\n",
    "        env = gym.make(self.env_name, render_mode=\"rgb_array\")  # creates the environment and agent\n",
    "        env = DummyVecEnv([lambda: env])  # creates a vectorized dummy environment\n",
    "        return env  # returns the created environment\n",
    "\n",
    "    def _build_dqn(self):  # A call to the function that builds the DQN model\n",
    "        model = DQN(self.policy, self.env, verbose=0, tensorboard_log=self.log_path, buffer_size=self.buffer_size)  # creates the DQN model\n",
    "        return model  # returns the created DQN model\n",
    "\n",
    "    def _play_one_episode(self):  # A call to the function that plays one episode\n",
    "        obs = self.env.reset()  # resets the environment\n",
    "        done = False  # sets the done flag\n",
    "        score = 0  # sets the score to zero\n",
    "\n",
    "        while not done:  # loops until the done flag is set\n",
    "            action = self.env.action_space.sample()  # selects an action from a sample space\n",
    "            obs, reward, done, _ = self.env.step([action])  # takes the action and returns the observation, reward, done, and info\n",
    "            score += reward  # Updates the score\n",
    "\n",
    "        return score  # returns the score value\n",
    "\n",
    "    def play_episodes(self, num_episodes=10, play_type=\"random\"):  # A call to the function that plays episodes\n",
    "        if play_type == \"random\":  # if the play type is random\n",
    "            print(f\"Playing the {self.agent_name} game randomly for {num_episodes} episodes\")  # prints the message\n",
    "            scores = [self._play_one_episode() for _ in range(num_episodes)]  # creates a list of scores\n",
    "            for episode, score in enumerate(scores, 1):  # loops through the list of scores\n",
    "                print(f\"Episode {episode}: {score}\")  # prints the score\n",
    "\n",
    "        if play_type == \"predict\":  # if the play type is predict\n",
    "            episode_rewards = []  # creates a list of episode rewards\n",
    "            frames = []  # creates a list of frames for the images\n",
    "\n",
    "            for episode in range(num_episodes):  # loops through the number of episodes\n",
    "                obs = self.env.reset()  # resets the environment\n",
    "                done = False  # sets the done flag\n",
    "                score = 0  # sets the score to zero\n",
    "\n",
    "                while not done:  # loops until the done flag is set\n",
    "                    action, _ = self.model.predict(obs)  # predicts the action to take from the observation\n",
    "                    obs, reward, done, _ = self.env.step(action)  # takes the action and returns the observation, reward, done, and info\n",
    "                    score += reward  # Updates the score\n",
    "                    frame = Image.fromarray(self.env.render())  # Captures the frame of image from the environment\n",
    "                    frame = np.array(frame)  # converts the frame to numpy\n",
    "                    frames.append(frame)  # adds the frame to the list\n",
    "\n",
    "                episode_rewards.append(score)  # adds the score to the list\n",
    "\n",
    "                print(f\"Episode {episode+1}: {score}\")  # prints the score\n",
    "\n",
    "            video_path = os.path.join(self.save_path, self.agent_name + \"_Agent_play\")  # video path\n",
    "\n",
    "            save_video(frames, video_path, fps=30, name_prefix=f\"{self.agent_name}-agent-play\")  # saves the video\n",
    "\n",
    "    def train(self, time_steps=None, stop_value=None):  # A call to the function that trains the agent\n",
    "        stop_callback = StopTrainingOnRewardThreshold(reward_threshold=stop_value, verbose=0)  # creates the stop callback, assigns the reward threshold so training can stop\n",
    "        eval_callback = EvalCallback(self.env, callback_on_new_best=stop_callback,\n",
    "                                     eval_freq=self.eval_frequency, best_model_save_path=self.save_path)  # creates the eval callback, checks if the reward has been achieved\n",
    "        self.model.learn(total_timesteps=time_steps, callback=eval_callback)  # trains the model\n",
    "\n",
    "    def evaluate_policy(self, episodes=None):  # A call to the function that evaluates the policy\n",
    "        mean_reward, reward_std = evaluate_policy(self.model, self.env, n_eval_episodes=episodes)  # evaluates the policy\n",
    "        print(f\"Mean reward over {episodes} episodes is {mean_reward} with a standard deviation of {reward_std}\")  # prints the mean reward and standard deviation\n",
    "\n",
    "    def close_env(self):  # A call to the function that closes the environment\n",
    "        self.env.close()  # closes the environment\n",
    "\n",
    "# Create the agent and create the environment\n",
    "CustomCartPole_agent = CustomCartPoleDQNAgent(agent_name=\"CustomCartPole\", env_name=\"CartPole-v1\")\n",
    "\n",
    "# Play the CartPole game randomly for 20 episodes\n",
    "CustomCartPole_agent.play_episodes(num_episodes=20)\n",
    "\n",
    "# Test out the agent with the CartPole game\n",
    "CustomCartPole_agent.train(time_steps=1000000, stop_value=500)\n",
    "\n",
    "# Test out the agent with the CartPole game\n",
    "CustomCartPole_agent.play_episodes(num_episodes=10, play_type=\"predict\")\n",
    "\n",
    "# Close the environment\n",
    "CustomCartPole_agent.close_env()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3171a6b-9397-49f6-b1ab-c54dcc614471",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPACE INVADERS GAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dffa28d-c82f-4c82-84ec-f74455f28a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing SpaceInvaders game and saving video for one episode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: [8.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (160, 210) to (160, 224) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=20000, episode_reward=359.00 +/- 113.68\n",
      "Episode length: 2898.60 +/- 991.34\n",
      "New best mean reward!\n",
      "Eval num_timesteps=40000, episode_reward=310.00 +/- 151.39\n",
      "Episode length: 2342.60 +/- 547.30\n",
      "Eval num_timesteps=60000, episode_reward=229.00 +/- 87.77\n",
      "Episode length: 3412.60 +/- 742.63\n",
      "Eval num_timesteps=80000, episode_reward=313.00 +/- 107.36\n",
      "Episode length: 3751.80 +/- 1205.31\n",
      "Eval num_timesteps=100000, episode_reward=240.00 +/- 160.84\n",
      "Episode length: 2629.40 +/- 787.56\n",
      "Eval num_timesteps=120000, episode_reward=198.00 +/- 77.76\n",
      "Episode length: 2349.40 +/- 334.97\n",
      "Eval num_timesteps=140000, episode_reward=24.00 +/- 17.15\n",
      "Episode length: 2269.00 +/- 374.83\n",
      "Eval num_timesteps=160000, episode_reward=137.00 +/- 116.43\n",
      "Episode length: 2154.20 +/- 842.01\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gym\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "import imageio\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, name=None, env_name=None, eval_freq=20000, buffer_size=1000):\n",
    "        self.name = name\n",
    "        self.env_name = env_name\n",
    "        self.eval_freq = eval_freq\n",
    "        self.buffer_size = buffer_size\n",
    "        self.log_path = os.path.join('C:/Users/Great Woman/Downloads/my_atari_games/Logs/DQN_' + self.name)\n",
    "        self.save_path = os.path.join('C:/Users/Great Woman/Downloads/my_atari_games/Saved_Models/DQN_' + self.name)\n",
    "        self.env = self.make_environment()\n",
    "        self.model = self._build_dqn()\n",
    "\n",
    "    def make_environment(self):\n",
    "        env = make_atari_env(self.env_name, n_envs=1, seed=0, monitor_dir=self.log_path)\n",
    "        env = VecFrameStack(env, n_stack=4)\n",
    "        return env\n",
    "\n",
    "    def _build_dqn(self):\n",
    "        model = DQN('CnnPolicy', self.env, buffer_size=self.buffer_size, verbose=0, tensorboard_log=self.log_path)\n",
    "        return model\n",
    "\n",
    "    def _play_one_episode(self):\n",
    "        obs = self.env.reset()\n",
    "        done = False\n",
    "        score = 0\n",
    "        frames = []\n",
    "\n",
    "        while not done:\n",
    "            action, _ = self.model.predict(obs)\n",
    "            obs, reward, done, _ = self.env.step(action)\n",
    "            score += reward\n",
    "            frame = Image.fromarray(self.env.render(mode='rgb_array'))\n",
    "            frame = np.array(frame)\n",
    "            frames.append(frame)\n",
    "\n",
    "        return score, frames\n",
    "\n",
    "    def play_episodes(self, num_episodes=10, play_type=\"random\"):\n",
    "        if play_type == \"random\":\n",
    "            print(f\"Playing the {self.name} game randomly for {num_episodes} episodes\")\n",
    "            scores = [self._play_one_episode()[0] for _ in range(num_episodes)]\n",
    "            for episode, score in enumerate(scores, 1):\n",
    "                print(f\"Episode {episode}: {score}\")\n",
    "\n",
    "        if play_type == \"predict\":\n",
    "            print(f\"Playing {self.name} game and saving video for one episode\")\n",
    "            score, frames = self._play_one_episode()\n",
    "            print(f\"Episode 1: {score}\")\n",
    "\n",
    "            # Save gameplay as an MP4 file\n",
    "            video_path = os.path.join(self.save_path, f\"{self.name}_episode_1.mp4\")\n",
    "            self._save_video(frames, video_path)\n",
    "\n",
    "            # Add zero episode\n",
    "            zero_frames = [frames[0]] * 30  # Repeat the first frame 30 times for a duration of 1 second\n",
    "            zero_video_path = os.path.join(self.save_path, f\"{self.name}_episode_0.mp4\")\n",
    "            self._save_video(zero_frames, zero_video_path)\n",
    "\n",
    "    def _save_video(self, frames, video_path, fps=30):\n",
    "        with imageio.get_writer(video_path, fps=fps) as video:\n",
    "            for frame in frames:\n",
    "                video.append_data(frame)\n",
    "\n",
    "    def train(self, time_steps=None, stop_value=None):\n",
    "        eval_callback = EvalCallback(self.env, best_model_save_path=self.save_path, log_path=self.log_path, eval_freq=self.eval_freq)\n",
    "        self.model.learn(total_timesteps=time_steps, callback=eval_callback)\n",
    "\n",
    "    def evaluate_policy(self, episodes=None):\n",
    "        mean_reward, reward_std = evaluate_policy(self.model, self.env, n_eval_episodes=episodes)\n",
    "        print(f\"Mean reward over {episodes} episodes is {mean_reward} with a standard deviation of {reward_std}\")\n",
    "\n",
    "    def load_best_model(self):\n",
    "        best_model = DQN.load(os.path.join(self.save_path, \"best_model\"))\n",
    "        return best_model\n",
    "\n",
    "    def save_model(self):\n",
    "        return self.model.save(os.path.join(self.save_path, \"final_model\"))\n",
    "\n",
    "    def close_env(self):\n",
    "        self.env.close()\n",
    "\n",
    "# SpaceInvaders\n",
    "SpaceInvaders_agent = DQNAgent(name=\"SpaceInvaders\", env_name=\"SpaceInvadersNoFrameskip-v4\")\n",
    "\n",
    "SpaceInvaders_agent.play_episodes(num_episodes=1, play_type=\"predict\")  # Play and save one episode\n",
    "\n",
    "SpaceInvaders_agent.train(time_steps=1000000, stop_value=1000)\n",
    "\n",
    "SpaceInvaders_agent.evaluate_policy(episodes=10)\n",
    "\n",
    "SpaceInvaders_agent.play_episodes(num_episodes=10, play_type=\"predict\")  # Play and save 10 episodes\n",
    "\n",
    "SpaceInvaders_agent.close_env()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc89591-bfc5-4228-bc7b-fb06569691d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PAC MAN GAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a66a88-7fd3-47d9-add6-7f60ca4476eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import gym\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from PIL import Image\n",
    "import imageio\n",
    "from gym.wrappers import ResizeObservation\n",
    "\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, name=None, env_name=None, eval_freq=20000, buffer_size=1000):\n",
    "        self.name = name\n",
    "        self.env_name = env_name\n",
    "        self.eval_freq = eval_freq\n",
    "        self.buffer_size = buffer_size\n",
    "        self.log_path = os.path.join('C:/Users/Great Woman/Downloads/my_atari_games/Logs/DQN_' + self.name)\n",
    "        self.save_path = os.path.join('C:/Users/Great Woman/Downloads/my_atari_games/Saved_Models/DQN_' + self.name)\n",
    "        self.env = self.make_environment()\n",
    "        self.model = self._build_dqn()\n",
    "\n",
    "    def make_environment(self):\n",
    "        env = gym.make(self.env_name, render_mode=\"rgb_array\")\n",
    "        env = ResizeObservation(env, 84)\n",
    "        return DummyVecEnv([lambda: env])\n",
    "\n",
    "    def _build_dqn(self):\n",
    "        model = DQN('CnnPolicy', self.env, buffer_size=self.buffer_size, verbose=0, tensorboard_log=self.log_path)\n",
    "        return model\n",
    "\n",
    "    def _play_one_episode(self, save_frames=False):\n",
    "        obs = self.env.reset()\n",
    "        done = False\n",
    "        score = 0\n",
    "        frames = []\n",
    "\n",
    "        while not done:\n",
    "            action, _ = self.model.predict(obs)\n",
    "            obs, reward, done, _ = self.env.step(action)\n",
    "            score += reward\n",
    "            if save_frames:\n",
    "                frame = Image.fromarray(self.env.render())\n",
    "                frame = np.array(frame)\n",
    "                frames.append(frame)\n",
    "\n",
    "        return score, frames\n",
    "\n",
    "    def play_episodes(self, num_episodes=10, play_type=\"random\"):\n",
    "        if play_type == \"random\":\n",
    "            print(f\"Playing the {self.name} game randomly for {num_episodes} episodes\")\n",
    "            scores = [self._play_one_episode()[0] for _ in range(num_episodes)]\n",
    "            for episode, score in enumerate(scores, 1):\n",
    "                print(f\"Episode {episode}: {score}\")\n",
    "\n",
    "        if play_type == \"predict\":\n",
    "            print(f\"Playing {self.name} game and saving video for one episode\")\n",
    "            score, frames = self._play_one_episode(save_frames=True)\n",
    "            print(f\"Episode 1: {score}\")\n",
    "\n",
    "            # Save gameplay as an MP4 file\n",
    "            video_path = os.path.join(self.save_path, f\"{self.name}_episode_1.mp4\")\n",
    "            self._save_video(frames, video_path)\n",
    "\n",
    "    def _save_video(self, frames, video_path, fps=30):\n",
    "        with imageio.get_writer(video_path, fps=fps) as video:\n",
    "            for frame in frames:\n",
    "                video.append_data(frame)\n",
    "\n",
    "    def train(self, time_steps=None, stop_value=None):\n",
    "        eval_callback = EvalCallback(self.env, best_model_save_path=self.save_path, log_path=self.log_path, eval_freq=self.eval_freq)\n",
    "        self.model.learn(total_timesteps=time_steps, callback=eval_callback)\n",
    "\n",
    "    def evaluate_policy(self, episodes=None):\n",
    "        mean_reward, reward_std = evaluate_policy(self.model, self.env, n_eval_episodes=episodes)\n",
    "        print(f\"Mean reward over {episodes} episodes is {mean_reward} with a standard deviation of {reward_std}\")\n",
    "\n",
    "    def load_best_model(self):\n",
    "        best_model = DQN.load(self.save_path + \"/best_model\")\n",
    "        return best_model\n",
    "\n",
    "    def save_model(self):\n",
    "        return self.model.save(self.save_path)\n",
    "\n",
    "    def close_env(self):\n",
    "        self.env.close()\n",
    "\n",
    "# Usage\n",
    "Pacman_agent = DQNAgent(name=\"Pacman\", env_name=\"MsPacmanNoFrameskip-v4\")\n",
    "\n",
    "# Play one episode and save the video\n",
    "Pacman_agent.play_episodes(num_episodes=1, play_type=\"predict\")\n",
    "\n",
    "# Train the model\n",
    "Pacman_agent.train(time_steps=1000000, stop_value=1000)\n",
    "\n",
    "# Save the trained model\n",
    "Pacman_agent.save_model()\n",
    "\n",
    "# Play multiple episodes\n",
    "Pacman_agent.play_episodes(num_episodes=10, play_type=\"random\")\n",
    "\n",
    "Pacman_agent.close_env()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0ea96d-964b-4fb9-b34e-36edbf38467e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
